{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sherlock import helpers\n",
    "from sherlock.features.preprocessing import extract_features, convert_string_lists_to_lists, prepare_feature_extraction\n",
    "from sherlock.deploy.train_sherlock import train_sherlock\n",
    "from sherlock.deploy.predict_sherlock import predict_sherlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n",
    "This will download the raw values and preprocessed files, the corresponding labels as well as a few other supporting files:\n",
    "- `download_data()` will download 3.6GB of data into the `data/` directory.\n",
    "- `prepare_feature_extraction()` will download +/- 800 MB of data into the `features/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the raw and preprocessed data into ../data/data.zip.\n",
      "Data was downloaded.\n",
      "Preparing feature extraction by downloading 2 files:\n",
      "        \n",
      " ../sherlock/features/glove.6B.50d.txt and \n",
      " ../sherlock/features/par_vec_trained_400.pkl.docvecs.vectors_docs.npy.\n",
      "        \n",
      "All files for extracting word and paragraph embeddings are present.\n"
     ]
    }
   ],
   "source": [
    "helpers.download_data()\n",
    "prepare_feature_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1114 20:08:39.666452  2128 deprecation.py:506] From c:\\users\\tiany\\anaconda3\\envs\\cs576\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1114 20:08:39.667453  2128 deprecation.py:506] From c:\\users\\tiany\\anaconda3\\envs\\cs576\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1114 20:08:39.668954  2128 deprecation.py:506] From c:\\users\\tiany\\anaconda3\\envs\\cs576\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Load Sherlock architecture and weights from files\n",
    "file = open('../models/sherlock_model.json', 'r')\n",
    "sherlock_file = file.read()\n",
    "sherlock = tf.keras.models.model_from_json(sherlock_file)\n",
    "file.close()\n",
    "\n",
    "sherlock.load_weights('../models/sherlock_weights.h5')\n",
    "sherlock.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp_samples = pd.read_csv('police_killings.csv',encoding = \"ISO-8859-1\")\n",
    "tmp_samples = pd.read_csv('adult.csv')\n",
    "#pd.DataFrame(tmp_samples.mean()).transpose().to_csv('tmp_samples.csv')\n",
    "#tmp_samples_means = pd.read_csv('tmp_samples.csv', index_col=0)\n",
    "#tmp_samples.fillna(tmp_samples_means.iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert input dataset to the required form\n",
    "index_range = range(len(tmp_samples.columns))\n",
    "df_value = pd.DataFrame(columns = ['value'],index = index_range)\n",
    "df_label = pd.DataFrame(columns = ['label'],index = index_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for i in tmp_samples.columns:\n",
    "    unique_val = list(tmp_samples[i].unique())\n",
    "    val_no_nan = [x for x in unique_val if str(x) != 'nan']\n",
    "    if len(val_no_nan) == 0:\n",
    "        # No value in any cell of this attribute\n",
    "        val_no_nan = [i]\n",
    "    df_value.at[idx,'value'] = str(val_no_nan)\n",
    "    df_label.at[idx,'label'] = i\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 154.51it/s]\n"
     ]
    }
   ],
   "source": [
    "test_samples_converted, y_test = convert_string_lists_to_lists(df_value, df_label,'value','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing feature extraction by downloading 2 files:\n",
      "        \n",
      " ../sherlock/features/glove.6B.50d.txt and \n",
      " ../sherlock/features/par_vec_trained_400.pkl.docvecs.vectors_docs.npy.\n",
      "        \n",
      "All files for extracting word and paragraph embeddings are present.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tiany\\anaconda3\\envs\\cs576\\lib\\site-packages\\pandas\\core\\strings.py:167: FutureWarning: Possible nested set at position 1\n",
      "  regex = re.compile(pat, flags=flags)\n"
     ]
    }
   ],
   "source": [
    "X_test = extract_features(test_samples_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict_sherlock(X_test, nn_id='sherlock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'fnlwgt', 'education', 'education.num',\n",
       "       'marital.status', 'occupation', 'relationship', 'race', 'sex',\n",
       "       'capital.gain', 'capital.loss', 'hours.per.week', 'native.country',\n",
       "       'income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_samples.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['day', 'owner', 'address', 'day', 'position', 'notes', 'address',\n",
       "       'family', 'album', 'sex', 'symbol', 'year', 'age', 'country',\n",
       "       'address'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'country','sex','age'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Gender based on Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'pip install git+git://github.com/clintval/gender_predictor.git'\n",
    "from gender_predictor import GenderPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names.pickle does not exist... creating\n",
      "names.zip does not exist... downloading\n",
      "names.pickle saved\n",
      "32,031 male names\n",
      "56,347 female names\n"
     ]
    }
   ],
   "source": [
    "gp = GenderPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier accuracy: 97.00%\n"
     ]
    }
   ],
   "source": [
    "gp.train_and_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp.classify('Gang')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age Summrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_age(x):\n",
    "    age = {'<16':0,'16-24':0,'25-34':0,\n",
    "          '35-44':0,'45-54':0,'55-64':0,'>64':0}\n",
    "    for i in x:\n",
    "        if i < 16:\n",
    "            age['<16'] += 1\n",
    "        elif i <= 24:\n",
    "            age['16-24'] += 1\n",
    "        elif i <= 34:\n",
    "            age['25-34'] += 1\n",
    "        elif i <= 44:\n",
    "            age['35-44'] += 1\n",
    "        elif i <= 54:\n",
    "            age['45-54'] += 1\n",
    "        elif i <= 64:\n",
    "            age['55-64'] += 1\n",
    "        else:\n",
    "            age['>64'] += 1\n",
    "    return age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<16': 0,\n",
       " '16-24': 5570,\n",
       " '25-34': 8479,\n",
       " '35-44': 8151,\n",
       " '45-54': 5853,\n",
       " '55-64': 3172,\n",
       " '>64': 1336}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_age(tmp_samples['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test whether categorical attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, it is categorical.\n"
     ]
    }
   ],
   "source": [
    "if len(tmp_samples['workclass'].unique()) / tmp_samples.shape[0] < 0.2:\n",
    "    print(\"Yes, it is categorical.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test whether these is a header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_header(path, n=5, th=0.9):\n",
    "    df1 = pd.read_csv(path, header='infer', nrows=n)\n",
    "    df2 = pd.read_csv(path, header=None, nrows=n)\n",
    "    sim = (df1.dtypes.values == df2.dtypes.values).mean()\n",
    "    return 'infer' if sim < th else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get matched sensitive attributes\n",
    "bias = [] # Format: sensitive, target\n",
    "unbias = []\n",
    "candidate = []\n",
    "target = []\n",
    "for i in zip(tmp_samples.columns,predicted_labels):\n",
    "    if i[1] in ['country','sex','age']:\n",
    "        candidate.append(i[0])\n",
    "    else:\n",
    "        target.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tiany\\anaconda3\\envs\\cs576\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "for tag in target:\n",
    "    for L in range(1, len(candidate)+1):\n",
    "        for subset in itertools.combinations(candidate, L):\n",
    "            idx = 0\n",
    "            attr_list = []\n",
    "            while idx < L:\n",
    "                attr_list.append(subset[idx])\n",
    "                idx += 1\n",
    "        \n",
    "            if L == 1 and np.issubdtype(type(tmp_samples[attr_list[0]][0]),int):\n",
    "                test = pd.DataFrame(columns = tmp_samples[(tag)].unique(),index = tmp_samples[attr_list[0]].drop_duplicates().values)\n",
    "                test.fillna(0, inplace = True)\n",
    "                for index, row in tmp_samples.iterrows():\n",
    "                    test.at[row[attr_list][0],row[tag]] += 1\n",
    "            else:\n",
    "                test = pd.DataFrame(columns = tmp_samples[(tag)].unique(),index = tmp_samples[attr_list].drop_duplicates().values)\n",
    "                test.fillna(0, inplace = True)\n",
    "                for index, row in tmp_samples.iterrows():\n",
    "                    test.at[tuple(row[attr_list]),row[tag]] += 1\n",
    "            \n",
    "            if chi2_contingency(test)[1] < 0.05:\n",
    "                bias.append([attr_list,tag])\n",
    "            else:\n",
    "                unbias.append([attr_list,tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_samples[['sex', 'hours.per.week']].drop_duplicates().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_samples.groupby(['sex', 'hours.per.week','income']).size().reset_index().rename(columns={0:''})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
