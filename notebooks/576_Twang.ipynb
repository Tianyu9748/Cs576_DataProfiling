{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sherlock import helpers\n",
    "from sherlock.features.preprocessing import extract_features, convert_string_lists_to_lists, prepare_feature_extraction\n",
    "from sherlock.deploy.train_sherlock import train_sherlock\n",
    "from sherlock.deploy.predict_sherlock import predict_sherlock\n",
    "from  profiling import generate_header\n",
    "from  profiling import identify_header\n",
    "from  profiling import preprocess_before_count\n",
    "from  profiling import filter_categories\n",
    "from  profiling import get_var_category\n",
    "from  profiling import process_df\n",
    "from  profiling import generate_df\n",
    "from  profiling import make_clickable\n",
    "from  profiling import read_info\n",
    "from  profiling import trans_age\n",
    "from  profiling import generate_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "import json\n",
    "#'pip install git+git://github.com/clintval/gender_predictor.git'\n",
    "from gender_predictor import GenderPredictor\n",
    "import itertools\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n",
    "This will download the raw values and preprocessed files, the corresponding labels as well as a few other supporting files:\n",
    "- `download_data()` will download 3.6GB of data into the `data/` directory.\n",
    "- `prepare_feature_extraction()` will download +/- 800 MB of data into the `features/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the raw and preprocessed data into ../data/data.zip.\n",
      "Data was downloaded.\n",
      "Preparing feature extraction by downloading 2 files:\n",
      "        \n",
      " ../sherlock/features/glove.6B.50d.txt and \n",
      " ../sherlock/features/par_vec_trained_400.pkl.docvecs.vectors_docs.npy.\n",
      "        \n",
      "All files for extracting word and paragraph embeddings are present.\n"
     ]
    }
   ],
   "source": [
    "helpers.download_data()\n",
    "prepare_feature_extraction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find all csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "PATH = \"F:/Data\"\n",
    "EXT = \"*.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_csv_files = [file\n",
    "                 #for path, subdir, files in os.walk(PATH)\n",
    "                 #for file in glob(os.path.join(path, EXT))]\n",
    "info = pd.DataFrame(columns = ['Dataset_ID','Age','Gender','Race','Ethnicity','Country','Maximal Uncovered Pattern(Sensitive)','Uncovered Attributes','Report'])\n",
    "processed_dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv_files = ['adult.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbe8b7d54814393b1678a72a06d9295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Summarize dataset'), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d848253829264d22a02ce9f8b99a7448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Generate report structure'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c6f8f2be234889a5c1c7b0c84a2596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Render HTML'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda8b6da0c7c4168b782e3a81cea1a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Export report to file'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1209 16:54:24.741297  7008 deprecation.py:506] From c:\\users\\tiany\\anaconda3\\envs\\cs576\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1209 16:54:24.742298  7008 deprecation.py:506] From c:\\users\\tiany\\anaconda3\\envs\\cs576\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1209 16:54:24.744300  7008 deprecation.py:506] From c:\\users\\tiany\\anaconda3\\envs\\cs576\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 63.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing feature extraction by downloading 2 files:\n",
      "        \n",
      " ../sherlock/features/glove.6B.50d.txt and \n",
      " ../sherlock/features/par_vec_trained_400.pkl.docvecs.vectors_docs.npy.\n",
      "        \n",
      "All files for extracting word and paragraph embeddings are present.\n"
     ]
    }
   ],
   "source": [
    "for file in all_csv_files:\n",
    "    #try:\n",
    "        #dataset_ID = file[8:17]\n",
    "        dataset_ID = 'adult.csv'\n",
    "        tmp_samples = pd.read_csv(file)\n",
    "        # Generate PDF report\n",
    "        profile = ProfileReport(tmp_samples, title=dataset_ID, explorative=True)\n",
    "        output_path = \"report/\" + dataset_ID +\".html\"\n",
    "        profile.to_file(output_path)\n",
    "        header, predicted_labels,candidate,name,gender,age,country,race,ethnicity,age_attribute = generate_candidate(tmp_samples.columns,file)\n",
    "        if not header:\n",
    "            tmp_samples.columns = predicted_labels\n",
    "        for i in age_attribute:\n",
    "            tmp_samples[i] = tmp_samples[i].apply(lambda x: trans_age(x))\n",
    "        tmp, gender = preprocess_before_count(tmp_samples,name,gender)\n",
    "        mup, uncover = process_df(tmp,candidate,age)\n",
    "        #mup_unsen = filter_mup_unsen()\n",
    "        tmp_info = generate_df(dataset_ID,age,gender,race,ethnicity,country,mup,uncover)\n",
    "        #tmp_info = tmp_info.style.format({'Report': make_clickable})\n",
    "        info = pd.concat([info, tmp_info], axis=0, sort=False)\n",
    "        output = info.copy()\n",
    "        #output = output.style.format({'Report': make_clickable})\n",
    "        output.to_excel(r'adult.xlsx', index = False)\n",
    "        processed_dataset.append(file)\n",
    "        #with open('processed.txt', 'w') as f:\n",
    "            #for item in processed_dataset:\n",
    "                #f.write(\"%s\\n\" % item)\n",
    "    #except:\n",
    "        #pass\n",
    "#info = info.style.format({'Report': make_clickable})\n",
    "#info.to_csv(r'info.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(1,len(uncover)+1):\n",
    "    att_comb = itertools.combinations(uncover, i)\n",
    "    for att in att_comb:\n",
    "        value = tmp[list(att)].drop_duplicates().values\n",
    "        if i == 1:\n",
    "            # Connect to root node\n",
    "            for val in value:\n",
    "                G.add_node(tuple(val))\n",
    "                G.add_edge('root',tuple(val))\n",
    "        else:\n",
    "            for val in value:\n",
    "                G.add_node(tuple(val))\n",
    "                for prev in list(G.nodes):\n",
    "                    if prev in val:\n",
    "                        G.add_edge(prev,tuple(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the output info.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = read_info('adult.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph\n",
    "from igraph import Graph, EdgeSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(uncover)+1):\n",
    "    att_comb = itertools.combinations(uncover, i)\n",
    "    for att in att_comb:\n",
    "        value = tmp[list(att)].drop_duplicates().values\n",
    "        if i == 1:\n",
    "            # Connect to root node\n",
    "            for val in value:\n",
    "                G.add_node(tuple(val))\n",
    "                G.add_edge('root',tuple(val))\n",
    "        else:\n",
    "            for val in value:\n",
    "                G.add_node(tuple(val))\n",
    "                for prev in list(G.nodes):\n",
    "                    if prev in val:\n",
    "                        G.add_edge(prev,tuple(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
